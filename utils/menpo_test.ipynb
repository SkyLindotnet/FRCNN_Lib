{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a4485f81c845>, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a4485f81c845>\"\u001b[0;36m, line \u001b[0;32m88\u001b[0m\n\u001b[0;31m    return fitter\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Fast R-CNN\n",
    "# Copyright (c) 2015 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import menpofit\n",
    "import menpofit\n",
    "import menpo.io as mio\n",
    "from menpo.feature import fast_dsift, igo\n",
    "from menpo.visualize import print_progress\n",
    "from menpofit.aam import HolisticAAM\n",
    "from menpowidgets import visualize_images\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    import menpo.io as mio\n",
    "    img = mio.import_image('/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/300w_cropped/01_Indoor/indoor_001.png')\n",
    "\n",
    "    if img.n_channels != 1:\n",
    "        img = img.as_greyscale()\n",
    "\n",
    "    img.landmarks['face'] = mio.import_landmark_file('/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/300w_cropped/01_Indoor/indoor_001.pts')\n",
    "\n",
    "    # objects return copies rather than mutating self, so we can chain calls\n",
    "    img = (img.crop_to_landmarks(group='face', boundary=10)\n",
    "           .rescale_landmarks_to_diagonal_range(100, group='face'))\n",
    "\n",
    "    # now lets take an image feature...\n",
    "    from menpo.feature import fast_dsift\n",
    "    img = fast_dsift(img)\n",
    "\n",
    "    # ...and extract the vector of pixels contained in the\n",
    "    # convex hull of the face...\n",
    "    vector = img.as_masked().constrain_mask_to_landmarks(group='face').as_vector()\n",
    "\n",
    "    print(type(vector), vector.shape)\n",
    "    # output: <class 'numpy.ndarray'> (3801,)\n",
    "\n",
    "def fit():\n",
    "    import menpo.io as mio\n",
    "    path_to_images = '/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/otherDB/lfpw/trainset'\n",
    "    training_images = mio.import_images(path_to_images, verbose=True)\n",
    "    \n",
    "    %matplotlib inline\n",
    "    from menpowidgets import visualize_images\n",
    "    visualize_images(training_images[3])\n",
    "    \n",
    "def fit_pre(image_paths):\n",
    "    import menpo.io as mio\n",
    "    from menpowidgets import visualize_images\n",
    "    from menpo.visualize import print_progress\n",
    "\n",
    "    training_images = []\n",
    "    for image_path in image_paths:\n",
    "        for img in print_progress(mio.import_images(image_path, verbose=True)):\n",
    "            visualize_images(img)\n",
    "            # convert to greyscale\n",
    "            if img.n_channels == 3:\n",
    "                img = img.as_greyscale()\n",
    "            # crop to landmarks bounding box with an extra 20% padding\n",
    "            img = img.crop_to_landmarks_proportion(0.2)\n",
    "            # rescale image if its diagonal is bigger than 400 pixels\n",
    "            d = img.diagonal()\n",
    "            if d > 400:\n",
    "                img = img.rescale(400.0 / d)\n",
    "#             %matplotlib inline\n",
    "#             visualize_images(img)\n",
    "            # append to list\n",
    "            training_images.append(img)\n",
    "        \n",
    "def train_AAM(training_images, feature=igo):\n",
    "    aam = HolisticAAM(training_images, reference_shape=None,\n",
    "                      diagonal=150, scales=(0.5, 1.0),\n",
    "                      holistic_features=feature, verbose=True,\n",
    "                      max_shape_components=20, max_appearance_components=150)\n",
    "    print(aam)\n",
    "    return aam\n",
    "\n",
    "def fitter_AAM(aam):\n",
    "    from menpofit.aam import LucasKanadeAAMFitter, WibergInverseCompositional\n",
    "\n",
    "    fitter = LucasKanadeAAMFitter(aam, lk_algorithm_cls=WibergInverseCompositional,\n",
    "                                  n_shape=[5, 20], n_appearance=[30, 150])\n",
    "    return fitter\n",
    "\n",
    "def pca(path_to_images):\n",
    "\n",
    "    path_to_lfpw = Path(path_to_images)\n",
    "\n",
    "    training_shapes = []\n",
    "    for lg in print_progress(mio.import_landmark_files(path_to_lfpw / '*.pts', verbose=True)):\n",
    "        training_shapes.append(lg['all'])\n",
    "    \n",
    "    %matplotlib inline\n",
    "    from menpowidgets import visualize_pointclouds\n",
    "    visualize_pointclouds(training_shapes)\n",
    "\n",
    "def test_AAM(fitter, test_images, test_gts):\n",
    "    for test_image in test_images:\n",
    "        test_gt = test_image.split('.')[0] + '.pts'\n",
    "        test_image = test_image.as_greyscale()\n",
    "    \n",
    "    pass\n",
    "              \n",
    "if __name__ == '__main__':\n",
    "    path_to_images = ['/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/otherDB/lfpw/trainset']\n",
    "    test_images = ['/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/300w_cropped/01_Indoor/indoor_110.png']                   \n",
    "    test_gts = ['/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/300w_cropped/01_Indoor/indoor_110.pts']                              \n",
    "    training_images = fit_pre(path_to_images)\n",
    "    aam = train_AAM(training_images)\n",
    "    fitter = fitter_AAM(aam)\n",
    "    print 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
