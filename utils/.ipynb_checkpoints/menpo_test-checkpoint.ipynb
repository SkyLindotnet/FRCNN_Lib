{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 811 assets, index the returned LazyList to import.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'PointCloud' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9e9da1ac640a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m#     %matplotlib inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m#     aam.view_aam_widget()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mpca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-9e9da1ac640a>\u001b[0m in \u001b[0;36mpca\u001b[0;34m(path_to_images)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mtraining_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_landmark_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_lfpw\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'*.pts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mtraining_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PointCloud' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Fast R-CNN\n",
    "# Copyright (c) 2015 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import menpofit\n",
    "import menpofit\n",
    "import menpo.io as mio\n",
    "from menpo.feature import fast_dsift, igo\n",
    "from menpo.visualize import print_progress\n",
    "from menpofit.aam import HolisticAAM\n",
    "from menpowidgets import visualize_images\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    import menpo.io as mio\n",
    "    img = mio.import_image('/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/300w_cropped/01_Indoor/indoor_001.png')\n",
    "\n",
    "    if img.n_channels != 1:\n",
    "        img = img.as_greyscale()\n",
    "\n",
    "    img.landmarks['face'] = mio.import_landmark_file('/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/300w_cropped/01_Indoor/indoor_001.pts')\n",
    "\n",
    "    # objects return copies rather than mutating self, so we can chain calls\n",
    "    img = (img.crop_to_landmarks(group='face', boundary=10)\n",
    "           .rescale_landmarks_to_diagonal_range(100, group='face'))\n",
    "\n",
    "    # now lets take an image feature...\n",
    "    from menpo.feature import fast_dsift\n",
    "    img = fast_dsift(img)\n",
    "\n",
    "    # ...and extract the vector of pixels contained in the\n",
    "    # convex hull of the face...\n",
    "    vector = img.as_masked().constrain_mask_to_landmarks(group='face').as_vector()\n",
    "\n",
    "    print(type(vector), vector.shape)\n",
    "    # output: <class 'numpy.ndarray'> (3801,)\n",
    "\n",
    "def fit():\n",
    "    import menpo.io as mio\n",
    "    path_to_images = '/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/otherDB/lfpw/trainset'\n",
    "    training_images = mio.import_images(path_to_images, verbose=True)\n",
    "    \n",
    "    %matplotlib inline\n",
    "    from menpowidgets import visualize_images\n",
    "    visualize_images(training_images[3])\n",
    "    \n",
    "def fit_pre(image_paths):\n",
    "    import menpo.io as mio\n",
    "    from menpowidgets import visualize_images\n",
    "    from menpo.visualize import print_progress\n",
    "\n",
    "    training_images = []\n",
    "    for image_path in image_paths:\n",
    "        for img in print_progress(mio.import_images(image_path, verbose=True)):\n",
    "            visualize_images(img)\n",
    "            # convert to greyscale\n",
    "            if img.n_channels == 3:\n",
    "                img = img.as_greyscale()\n",
    "            # crop to landmarks bounding box with an extra 20% padding\n",
    "            img = img.crop_to_landmarks_proportion(0.2)\n",
    "            # rescale image if its diagonal is bigger than 400 pixels\n",
    "            d = img.diagonal()\n",
    "            if d > 400:\n",
    "                img = img.rescale(400.0 / d)\n",
    "#             %matplotlib inline\n",
    "#             visualize_images(img)\n",
    "            # append to list\n",
    "            training_images.append(img)\n",
    "        \n",
    "def train_AAM(training_images, feature=igo):\n",
    "    aam = HolisticAAM(training_images, reference_shape=None,\n",
    "                      diagonal=150, scales=(0.5, 1.0),\n",
    "                      holistic_features=feature, verbose=True,\n",
    "                      max_shape_components=20, max_appearance_components=150)\n",
    "    print(aam)\n",
    "    return aam\n",
    "\n",
    "def fitter_AAM(aam):\n",
    "    from menpofit.aam import LucasKanadeAAMFitter, WibergInverseCompositional\n",
    "\n",
    "    fitter = LucasKanadeAAMFitter(aam, lk_algorithm_cls=WibergInverseCompositional,\n",
    "                                  n_shape=[5, 20], n_appearance=[30, 150]\n",
    "    return fitter\n",
    "\n",
    "def pca(path_to_images):\n",
    "\n",
    "    path_to_lfpw = Path(path_to_images)\n",
    "\n",
    "    training_shapes = []\n",
    "    for lg in print_progress(mio.import_landmark_files(path_to_lfpw / '*.pts', verbose=True)):\n",
    "        training_shapes.append(lg['all'])\n",
    "    \n",
    "    %matplotlib inline\n",
    "    from menpowidgets import visualize_pointclouds\n",
    "    visualize_pointclouds(training_shapes)\n",
    "\n",
    "def test_AAM(fitter, test_images, test_gts):\n",
    "    image = image.as_greyscale()\n",
    "    pass\n",
    "                                  \n",
    "if __name__ == '__main__':\n",
    "    path_to_images = ['/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/otherDB/lfpw/trainset']\n",
    "    test_images = ['/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/300w_cropped/01_Indoor/indoor_110.png']                   \n",
    "    test_gts = ['/home/sean/workplace/221/py-R-FCN-test/data/DB/face/300-w_face/300w_cropped/01_Indoor/indoor_110.pts']                              \n",
    "    training_images = fit_pre(path_to_images)\n",
    "    aam = train_AAM(training_images)\n",
    "    fitter = fitter_AAM(aam)\n",
    "    print 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
